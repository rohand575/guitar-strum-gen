{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Neural Prompt Parser Training (DistilBERT)\n",
    "\n",
    "**Guitar Strum Generator - Master Thesis**  \n",
    "**Author:** Rohan Rajendra Dhanawade\n",
    "\n",
    "This notebook trains a **DistilBERT-based neural network** to extract musical features from natural language prompts.\n",
    "\n",
    "## What is DistilBERT?\n",
    "- A **66 million parameter** transformer model\n",
    "- Pre-trained on **billions of words** (Wikipedia + BookCorpus)\n",
    "- Understands **semantic meaning** of text\n",
    "- We **fine-tune** it on YOUR music dataset\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "Input: \"moody atmospheric indie track\"\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚    DistilBERT Encoder   â”‚  â† 66M parameters, pre-trained\n",
    "â”‚   (6 transformer layers)â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "            â”‚\n",
    "    [CLS] embedding (768-dim)\n",
    "            â”‚\n",
    "      â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”\n",
    "      â”‚           â”‚\n",
    "      â–¼           â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Emotion  â”‚ â”‚  Genre   â”‚\n",
    "â”‚  Head    â”‚ â”‚  Head    â”‚\n",
    "â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜\n",
    "     â”‚            â”‚\n",
    "     â–¼            â–¼\n",
    "\"melancholic\"   \"indie\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (Colab has most pre-installed)\n",
    "!pip install transformers -q\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "from google.colab import files\n",
    "\n",
    "# Check GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Your Dataset\n",
    "\n",
    "Upload your `train.jsonl` file from the Chat 4 dataset construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Upload from your computer\n",
    "print(\"Upload your train.jsonl file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Show uploaded file\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"Uploaded: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Clone from your GitHub (alternative)\n",
    "# !git clone https://github.com/rohand575/guitar-strum-gen.git\n",
    "# TRAIN_PATH = 'guitar-strum-gen/data/processed/train.jsonl'\n",
    "\n",
    "# If you uploaded, use this:\n",
    "TRAIN_PATH = 'train.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Constants and Label Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These MUST match your schema.py!\n",
    "VALID_EMOTIONS = [\n",
    "    'upbeat', 'melancholic', 'mellow', 'energetic',\n",
    "    'peaceful', 'dramatic', 'hopeful', 'nostalgic'\n",
    "]\n",
    "\n",
    "VALID_GENRES = [\n",
    "    'pop', 'rock', 'folk', 'ballad', 'country',\n",
    "    'blues', 'jazz', 'indie', 'acoustic'\n",
    "]\n",
    "\n",
    "# Create label mappings\n",
    "EMOTION_TO_IDX = {e: i for i, e in enumerate(VALID_EMOTIONS)}\n",
    "IDX_TO_EMOTION = {i: e for e, i in EMOTION_TO_IDX.items()}\n",
    "\n",
    "GENRE_TO_IDX = {g: i for i, g in enumerate(VALID_GENRES)}\n",
    "IDX_TO_GENRE = {i: g for g, i in GENRE_TO_IDX.items()}\n",
    "\n",
    "NUM_EMOTIONS = len(VALID_EMOTIONS)  # 8\n",
    "NUM_GENRES = len(VALID_GENRES)      # 9\n",
    "\n",
    "print(f\"Emotion classes: {NUM_EMOTIONS}\")\n",
    "print(f\"Genre classes: {NUM_GENRES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for training the neural prompt parser.\n",
    "    \n",
    "    Converts JSONL samples into tensors:\n",
    "    - input_ids: Tokenized prompt\n",
    "    - attention_mask: Which tokens are real\n",
    "    - emotion_label: Integer class (0-7)\n",
    "    - genre_label: Integer class (0-8)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str, tokenizer, max_length: int = 128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.samples = []\n",
    "        \n",
    "        with open(data_path, 'r') as f:\n",
    "            for line in f:\n",
    "                self.samples.append(json.loads(line))\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Tokenize prompt\n",
    "        encoding = self.tokenizer(\n",
    "            sample['prompt'],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Get labels\n",
    "        emotion_label = EMOTION_TO_IDX.get(\n",
    "            sample.get('emotion', 'mellow').lower(),\n",
    "            EMOTION_TO_IDX['mellow']\n",
    "        )\n",
    "        genre_label = GENRE_TO_IDX.get(\n",
    "            sample.get('genre', 'pop').lower(),\n",
    "            GENRE_TO_IDX['pop']\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'emotion_label': torch.tensor(emotion_label, dtype=torch.long),\n",
    "            'genre_label': torch.tensor(genre_label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define the Neural Model (DistilBERT + Classification Heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertPromptParser(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Prompt Parser using DistilBERT.\n",
    "    \n",
    "    This is a REAL neural network:\n",
    "    - 66M parameters in DistilBERT encoder\n",
    "    - Classification heads for emotion and genre\n",
    "    - Trained on YOUR music dataset!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dropout_rate: float = 0.3, freeze_bert: bool = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pre-trained DistilBERT\n",
    "        print(\"Loading DistilBERT (66M parameters)...\")\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        \n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"BERT frozen (feature extraction mode)\")\n",
    "        else:\n",
    "            print(\"BERT trainable (fine-tuning mode)\")\n",
    "        \n",
    "        hidden_size = self.bert.config.hidden_size  # 768\n",
    "        \n",
    "        # Emotion classification head\n",
    "        self.emotion_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, NUM_EMOTIONS)\n",
    "        )\n",
    "        \n",
    "        # Genre classification head  \n",
    "        self.genre_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, NUM_GENRES)\n",
    "        )\n",
    "        \n",
    "        # Print parameter counts\n",
    "        bert_params = sum(p.numel() for p in self.bert.parameters())\n",
    "        head_params = sum(p.numel() for p in self.emotion_classifier.parameters())\n",
    "        head_params += sum(p.numel() for p in self.genre_classifier.parameters())\n",
    "        print(f\"DistilBERT params: {bert_params:,}\")\n",
    "        print(f\"Classification heads: {head_params:,}\")\n",
    "        print(f\"Total: {bert_params + head_params:,}\")\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERT embeddings\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use [CLS] token (index 0) as sentence representation\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # [batch, 768]\n",
    "        \n",
    "        # Classification\n",
    "        emotion_logits = self.emotion_classifier(cls_embedding)\n",
    "        genre_logits = self.genre_classifier(cls_embedding)\n",
    "        \n",
    "        return emotion_logits, genre_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Initialize Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Demo tokenization\n",
    "demo_text = \"moody atmospheric indie track\"\n",
    "tokens = tokenizer.tokenize(demo_text)\n",
    "print(f\"\\nDemo tokenization:\")\n",
    "print(f\"  Input: '{demo_text}'\")\n",
    "print(f\"  Tokens: {tokens}\")\n",
    "print(f\"  Token IDs: {tokenizer.encode(demo_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = DistilBertPromptParser(freeze_bert=False)\n",
    "model.to(device)\n",
    "\n",
    "print(f\"\\nModel on: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "train_dataset = PromptDataset(TRAIN_PATH, tokenizer)\n",
    "\n",
    "# Create dataloader\n",
    "BATCH_SIZE = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(f\"\\nBatches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Training Loop ðŸ”¥\n",
    "\n",
    "**This is where the LEARNING happens!**\n",
    "\n",
    "The model:\n",
    "1. Reads prompts from your dataset\n",
    "2. Makes predictions (emotion, genre)\n",
    "3. Compares to ground truth labels\n",
    "4. Calculates loss (how wrong it was)\n",
    "5. **Backpropagates** to adjust 66M+ weights\n",
    "6. Repeats until accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-5  # Standard for BERT fine-tuning\n",
    "\n",
    "# Loss function (Cross-Entropy for classification)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (AdamW is standard for transformers)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"Training for {EPOCHS} epochs\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "history = {'loss': [], 'emotion_acc': [], 'genre_acc': []}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING STARTED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_emotion = 0\n",
    "    correct_genre = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        # Move to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        emotion_labels = batch['emotion_label'].to(device)\n",
    "        genre_labels = batch['genre_label'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        emotion_logits, genre_logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        # Calculate loss\n",
    "        emotion_loss = criterion(emotion_logits, emotion_labels)\n",
    "        genre_loss = criterion(genre_logits, genre_labels)\n",
    "        loss = emotion_loss + genre_loss\n",
    "        \n",
    "        # Backward pass (THIS IS THE LEARNING!)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        emotion_preds = torch.argmax(emotion_logits, dim=-1)\n",
    "        genre_preds = torch.argmax(genre_logits, dim=-1)\n",
    "        \n",
    "        correct_emotion += (emotion_preds == emotion_labels).sum().item()\n",
    "        correct_genre += (genre_preds == genre_labels).sum().item()\n",
    "        total_samples += len(emotion_labels)\n",
    "    \n",
    "    # Epoch stats\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    emotion_acc = correct_emotion / total_samples * 100\n",
    "    genre_acc = correct_genre / total_samples * 100\n",
    "    \n",
    "    history['loss'].append(avg_loss)\n",
    "    history['emotion_acc'].append(emotion_acc)\n",
    "    history['genre_acc'].append(genre_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"  Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Emotion Acc: {emotion_acc:.1f}%\")\n",
    "    print(f\"  Genre Acc: {genre_acc:.1f}%\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE! ðŸŽ‰\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['loss'], 'b-o')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "\n",
    "# Emotion Accuracy\n",
    "axes[1].plot(history['emotion_acc'], 'g-o')\n",
    "axes[1].set_title('Emotion Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_ylim([0, 100])\n",
    "\n",
    "# Genre Accuracy\n",
    "axes[2].plot(history['genre_acc'], 'r-o')\n",
    "axes[2].set_title('Genre Accuracy')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Accuracy (%)')\n",
    "axes[2].set_ylim([0, 100])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Test the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prompt: str) -> dict:\n",
    "    \"\"\"Make prediction on a single prompt.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize\n",
    "    encoding = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        emotion_logits, genre_logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        emotion_probs = torch.softmax(emotion_logits, dim=-1)\n",
    "        genre_probs = torch.softmax(genre_logits, dim=-1)\n",
    "        \n",
    "        emotion_idx = torch.argmax(emotion_probs, dim=-1).item()\n",
    "        genre_idx = torch.argmax(genre_probs, dim=-1).item()\n",
    "    \n",
    "    return {\n",
    "        'prompt': prompt,\n",
    "        'emotion': IDX_TO_EMOTION[emotion_idx],\n",
    "        'emotion_confidence': emotion_probs[0, emotion_idx].item(),\n",
    "        'genre': IDX_TO_GENRE[genre_idx],\n",
    "        'genre_confidence': genre_probs[0, genre_idx].item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompts - including ambiguous ones!\n",
    "test_prompts = [\n",
    "    \"sad folk song in E minor\",\n",
    "    \"upbeat pop in G major\",\n",
    "    \"something chill for the evening\",  # Ambiguous - no explicit labels!\n",
    "    \"moody atmospheric vibes\",           # Very ambiguous!\n",
    "    \"driving rock anthem\",\n",
    "    \"peaceful acoustic morning coffee\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING TRAINED MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    result = predict(prompt)\n",
    "    print(f\"\\nPrompt: '{result['prompt']}'\")\n",
    "    print(f\"  â†’ Emotion: {result['emotion']} ({result['emotion_confidence']:.1%})\")\n",
    "    print(f\"  â†’ Genre: {result['genre']} ({result['genre_confidence']:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model checkpoint\n",
    "SAVE_PATH = 'neural_parser_checkpoint.pt'\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'emotion_to_idx': EMOTION_TO_IDX,\n",
    "    'idx_to_emotion': IDX_TO_EMOTION,\n",
    "    'genre_to_idx': GENRE_TO_IDX,\n",
    "    'idx_to_genre': IDX_TO_GENRE,\n",
    "    'history': history\n",
    "}, SAVE_PATH)\n",
    "\n",
    "print(f\"Model saved to {SAVE_PATH}\")\n",
    "\n",
    "# Download the model\n",
    "files.download(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've just trained a **real neural network** for your thesis!\n",
    "\n",
    "### What happened:\n",
    "1. **DistilBERT** (66M parameters) converted your prompts to embeddings\n",
    "2. **Classification heads** learned to predict emotion/genre from embeddings\n",
    "3. **Backpropagation** adjusted weights based on your dataset labels\n",
    "4. Model now understands **semantic meaning** of music descriptions\n",
    "\n",
    "### Key differences from rule-based:\n",
    "| Rule-Based | Neural (DistilBERT) |\n",
    "|------------|---------------------|\n",
    "| If-else logic | 66M learned parameters |\n",
    "| Exact keyword match | Semantic understanding |\n",
    "| \"sad\" â†’ melancholic | \"gloomy rainy day\" â†’ melancholic |\n",
    "| Can't generalize | Handles unseen phrasings |\n",
    "\n",
    "### For your thesis:\n",
    "- This is the **AI/ML component** of the prompt parser\n",
    "- Report training curves in your Results chapter\n",
    "- Compare neural vs rule-based accuracy\n",
    "- The hybrid system uses both!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
